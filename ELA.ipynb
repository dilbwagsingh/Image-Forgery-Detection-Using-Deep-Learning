{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def convert_to_ela_image(image):\n",
    "        quality=90;\n",
    "        #im=image.convert('RGB')\n",
    "        im = Image.fromarray(image,'RGB')\n",
    "        im.save('resaved.jpg','JPEG', quality=quality)\n",
    "        resaved_im=Image.open('resaved.jpg')\n",
    "        ela_im = ImageChops.difference(im, resaved_im)\n",
    "        os.remove('resaved.jpg')\n",
    "        extrema = ela_im.getextrema()\n",
    "        max_diff = max([ex[1] for ex in extrema])\n",
    "        if max_diff == 0:\n",
    "            max_diff = 1\n",
    "        scale = 255.0/max_diff \n",
    "\n",
    "        ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
    "        return np.array(ela_im,dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 60, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               7373056   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 7,401,634\n",
      "Trainable params: 7,401,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(5,5),padding='valid',activation='relu',input_shape=(128,128,3)),\n",
    "    tf.keras.layers.Conv2D(32,(5,5),strides=(2,2),padding='valid',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2,2),strides=None,padding='valid',data_format='channels_last'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2,activation='softmax')\n",
    "]);\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(lr=0.01,rho=0.9, epsilon=1e-08, decay=0.0),loss='categorical_crossentropy',metrics=['accuracy']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip='data.zip';\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('Data')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('Data/data')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data2');\n",
    "os.mkdir('data2/tamp');\n",
    "os.mkdir('data2/scale');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=os.listdir('Data/data');\n",
    "for i in range(0,len(names)):\n",
    "    file=names[i];\n",
    "    path='Data/data/'+file;\n",
    "    if(file.find('tamp') != -1):\n",
    "        shutil.move(path,'data2/tamp/');\n",
    "    else:\n",
    "        shutil.move(path,'data2/scale/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "1301\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data2/tamp')))\n",
    "print(len(os.listdir('data2/scale')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data3');\n",
    "os.mkdir('data3/training');\n",
    "os.mkdir('data3/testing');\n",
    "os.mkdir('data3/training/tamp');\n",
    "os.mkdir('data3/training/scale');\n",
    "os.mkdir('data3/testing/tamp');\n",
    "os.mkdir('data3/testing/scale');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    listing=os.listdir(SOURCE);\n",
    "    random.sample(listing,len(listing));\n",
    "    list2=listing[0:int(len(listing)-SPLIT_SIZE*len(listing))];\n",
    "    list3=list(set(listing)-set(list2));\n",
    "    c=0;\n",
    "    for i in list2:\n",
    "        if(os.path.getsize(SOURCE+i)>0):\n",
    "            copyfile(SOURCE+i,TRAINING+i);\n",
    "    for i in list3:\n",
    "        if(os.path.getsize(SOURCE+i)>0):\n",
    "            copyfile(SOURCE+i,TESTING+i);\n",
    "\n",
    "tamp_SOURCE_DIR = 'data2/tamp/'\n",
    "TRAINING_tamp_DIR = 'data3/training/tamp/'\n",
    "TESTING_tamp_DIR = 'data3/testing/tamp/'\n",
    "scale_SOURCE_DIR = 'data2/scale/'\n",
    "TRAINING_scale_DIR = 'data3/training/scale/'\n",
    "TESTING_scale_DIR = 'data3/testing/scale/'\n",
    "split_size = .1\n",
    "split_data(tamp_SOURCE_DIR, TRAINING_tamp_DIR, TESTING_tamp_DIR, split_size)\n",
    "split_data(scale_SOURCE_DIR, TRAINING_scale_DIR, TESTING_scale_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('data3/training/scale')))\n",
    "print(len(os.listdir('data3/testing/scale')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1799 images belonging to 2 classes.\n",
      "Found 201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "TRAINING_DIR = 'data3/training'\n",
    "train_datagen = ImageDataGenerator(\n",
    "      preprocessing_function=convert_to_ela_image,\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,target_size=(128,128),batch_size=5,class_mode='categorical')\n",
    "VALIDATION_DIR = 'data3/testing'\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.0);\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,target_size=(128,128),batch_size=10,class_mode='categorical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "211/359 [================>.............] - ETA: 1:09 - loss: 10.7389 - accuracy: 0.6480"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=359,  # 2000 images = batch_size * steps\n",
    "      epochs=12,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
